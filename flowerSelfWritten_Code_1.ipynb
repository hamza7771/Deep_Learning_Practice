{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "flowerSelfWritten Code.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2M5vi7vccR3Y",
        "outputId": "d78ec997-9c9a-4330-f09c-e5cdbaee70f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/AI Learning Hard MODE/FlowerRecognition/flowers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GTY3RGMctSj",
        "outputId": "c22606d9-8882-4b85-846b-7e59c8493c4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/AI Learning Hard MODE/FlowerRecognition/flowers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.listdir('../flowers'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWTa089cckGD",
        "outputId": "8fd4a771-ab98-4453-f093-15ab036cb8bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['sunflower', 'rose', 'tulip', 'daisy', 'dandelion', 'rose.jpg', 'dandelion.jpg', 'A2.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
      ],
      "metadata": {
        "id": "uyJ9ds7fc9Vv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        validation_split=0.4\n",
        "        )\n",
        "#test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '../flowers',\n",
        "        target_size=(320, 240),\n",
        "        batch_size=32,\n",
        "        subset='training',\n",
        "        class_mode='categorical',\n",
        "        shuffle=True\n",
        "        )\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "        '../flowers',\n",
        "        target_size=(320, 240),\n",
        "        batch_size=32,\n",
        "        subset='validation',\n",
        "        class_mode='categorical',\n",
        "        shuffle=True\n",
        "        )\n",
        "\n",
        "#model.fit(train_generator,steps_per_epoch=2000,epochs=50,validation_data=validation_generator,validation_steps=800)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBPyLlYzX3XI",
        "outputId": "fada72b0-88ab-4754-d99e-b76e29e740fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 300 images belonging to 5 classes.\n",
            "Found 200 images belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(train_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35mKSC6ndAcs",
        "outputId": "d3d226e3-e99a-464d-88cd-c18d3c663964"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "keras.preprocessing.image.DirectoryIterator"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "model=models.Sequential()\n",
        "model.add(layers.Conv2D(256,(3,3),activation='relu',input_shape=(320,240,3)))\n",
        "model.add(layers.MaxPooling2D(2,2))\n",
        "\n",
        "\n",
        "model.add(layers.Conv2D(256,(3,3),activation='relu'))\n",
        "model.add(layers.MaxPooling2D(2,2))\n",
        "\n",
        "\n",
        "\n",
        "model.add(layers.Conv2D(128,(3,3),activation='relu'))\n",
        "model.add(layers.MaxPooling2D(2,2))\n",
        "\n",
        "\n",
        "\n",
        "model.add(layers.Conv2D(128,(3,3),activation='relu'))\n",
        "model.add(layers.MaxPooling2D(2,2))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dropout(0.5))\n",
        "\n",
        "\n",
        "model.add(layers.Dense(64,activation='relu'))\n",
        "model.add(layers.Dense(5,activation='softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "9HyA0iFwz3a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "860ab9e8-e28b-47c5-8d9c-128ae3eefeae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 318, 238, 256)     7168      \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 159, 119, 256)    0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 157, 117, 256)     590080    \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 78, 58, 256)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 76, 56, 128)       295040    \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 38, 28, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 36, 26, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 18, 13, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 29952)             0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 29952)             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                1916992   \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,957,189\n",
            "Trainable params: 2,957,189\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ILbe6o1ygtAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tensorflow.device ('/device:GPU:0'):\n",
        "  results=model.fit(train_generator,steps_per_epoch=10,epochs=50,validation_data=validation_generator,validation_steps=10,verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzL_SNoqhV46",
        "outputId": "e7d0bc77-758e-48dc-a294-8543a48f9a38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6653 - accuracy: 0.7167WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10 batches). You may need to use the repeat() function when building your dataset.\n",
            "10/10 [==============================] - 22s 2s/step - loss: 0.6653 - accuracy: 0.7167 - val_loss: 1.3496 - val_accuracy: 0.5950\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.6020 - accuracy: 0.8233\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.5303 - accuracy: 0.8133\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.4321 - accuracy: 0.8400\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.5122 - accuracy: 0.8133\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.4606 - accuracy: 0.8167\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 10s 1s/step - loss: 0.3484 - accuracy: 0.8700\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.5972 - accuracy: 0.7900\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.3186 - accuracy: 0.8767\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.2109 - accuracy: 0.9100\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.4307 - accuracy: 0.8600\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 10s 968ms/step - loss: 0.3164 - accuracy: 0.8833\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 10s 1s/step - loss: 0.3021 - accuracy: 0.9167\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.3629 - accuracy: 0.8700\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.2073 - accuracy: 0.9400\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.2241 - accuracy: 0.9167\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.3386 - accuracy: 0.8900\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.2798 - accuracy: 0.9233\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.1888 - accuracy: 0.9367\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.1756 - accuracy: 0.9367\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.2714 - accuracy: 0.9233\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.2731 - accuracy: 0.9167\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.1200 - accuracy: 0.9567\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.2519 - accuracy: 0.9233\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.1114 - accuracy: 0.9533\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.4336 - accuracy: 0.9100\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 10s 1s/step - loss: 0.1060 - accuracy: 0.9600\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.0850 - accuracy: 0.9600\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.0548 - accuracy: 0.9833\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 10s 970ms/step - loss: 0.4869 - accuracy: 0.8867\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.1070 - accuracy: 0.9733\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.0366 - accuracy: 0.9900\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 10s 968ms/step - loss: 0.0923 - accuracy: 0.9667\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 10s 1s/step - loss: 0.0965 - accuracy: 0.9733\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.2521 - accuracy: 0.9367\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.1723 - accuracy: 0.9567\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.0666 - accuracy: 0.9867\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.1015 - accuracy: 0.9733\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.1473 - accuracy: 0.9467\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.1514 - accuracy: 0.9700\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.0371 - accuracy: 0.9933\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.3388 - accuracy: 0.9233\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.1645 - accuracy: 0.9367\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.1003 - accuracy: 0.9733\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 10s 966ms/step - loss: 0.0170 - accuracy: 0.9967\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.0452 - accuracy: 0.9867\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.2391 - accuracy: 0.9400\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.1243 - accuracy: 0.9633\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.0209 - accuracy: 0.9933\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.2085 - accuracy: 0.9533\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(validation_generator)"
      ],
      "metadata": {
        "id": "YThmE2iEz3b3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.listdir('../flowers'))"
      ],
      "metadata": {
        "id": "-PLjCv71ot0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#To resize original image to standard format and saving it\n",
        "from PIL import Image\n",
        "img1 = Image.open('dandelion.jpg')\n",
        "imResize = img1.resize((240,320), Image.ANTIALIAS)\n",
        "imResize.save('A2.jpg', 'JPEG', quality=90)\n"
      ],
      "metadata": {
        "id": "hFdp6jHon2qP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "predictimg=cv2.imread(\"A2.jpg\",1)\n",
        "predictimg=np.array(predictimg)\n",
        "plt.imshow(predictimg)\n",
        "predictimg=predictimg/255.0\n",
        "\n",
        "predictimg = np.expand_dims(predictimg, axis=0)\n",
        "predictimg.shape"
      ],
      "metadata": {
        "id": "-MrxOMqgpFqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predition=model.predict(predictimg)\n",
        "species=['tulip','sunflower', 'rose', 'dandelion', 'daisy']\n",
        "predition=np.squeeze(predition)\n",
        "print(predition)\n",
        "predIndex=np.argmax(predition)\n",
        "print(\"The Species of given image is\",species[predIndex])"
      ],
      "metadata": {
        "id": "dR1DNaFYpXTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(results.history['accuracy'])\n",
        "plt.plot(results.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "I3TMJAROujlO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def read_images(directory):\n",
        "#   for img in glob.glob(directory+\"/*.jpg*\"):\n",
        "#     image=cv2.imread(img)\n",
        "#     resized_img=cv2.resize(image/255,(240,320))\n",
        "#     yield resized_img\n"
      ],
      "metadata": {
        "id": "UqYChTbneA3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# resized_img1=np.array(list(read_images(IMG_DIR1)))\n",
        "# resized_img2=np.array(list(read_images(IMG_DIR2)))\n",
        "# resized_img3=np.array(list(read_images(IMG_DIR3)))\n",
        "# resized_img4=np.array(list(read_images(IMG_DIR4)))\n",
        "# resized_img5=np.array(list(read_images(IMG_DIR5)))"
      ],
      "metadata": {
        "id": "YA7iodfF2Fdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#resized_img5.shape"
      ],
      "metadata": {
        "id": "AdAIzGTl0MG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "57K6ST9egE52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# label1=np.ones((resized_img1.shape[0],1))\n",
        "# label2=np.ones((resized_img2.shape[0],1))*2\n",
        "# label3=np.ones((resized_img3.shape[0],1))*3\n",
        "# label4=np.ones((resized_img4.shape[0],1))*4\n",
        "# label5=np.ones((resized_img5.shape[0],1))*5"
      ],
      "metadata": {
        "id": "kA9V10d8mWiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qGUyah0RgFWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data=np.concatenate((resized_img1,resized_img2,resized_img3,resized_img4,resized_img5))\n",
        "# label=np.concatenate((label1,label2,label3,label4,label5))"
      ],
      "metadata": {
        "id": "vtP2-EsLfL3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# np.random.seed(101)\n",
        "# mask=np.random.rand(len(data)) < 0.7\n",
        "# train_data= data[mask]\n",
        "# test_data=data[~mask]\n",
        "# train_label= label[mask]\n",
        "# test_label=label[~mask]\n"
      ],
      "metadata": {
        "id": "ELHZu21531pE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(test_label.shape)"
      ],
      "metadata": {
        "id": "FDdqZVQQJZ4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from tensorflow.keras.utils import to_categorical\n",
        "#train_label1=to_categorical(train_label)\n",
        "#test_label1=to_categorical(test_label)"
      ],
      "metadata": {
        "id": "4cNDATZoLe95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_label1"
      ],
      "metadata": {
        "id": "X-1SmpZFLf6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from keras import models\n",
        "# from keras import layers\n",
        "# model=models.Sequential()\n",
        "# model.add(layers.Dense(64,activation='relu',input_shape=(320*20*3),))\n",
        "# model.add(layers.Dense(64,activation='relu'))\n",
        "# model.add(layers.Dense(64,activation='softmax'))"
      ],
      "metadata": {
        "id": "3jddKyWMLgBi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}